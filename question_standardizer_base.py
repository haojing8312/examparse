"""
é¢˜ç›®æ ‡å‡†åŒ–åŸºç¡€æ¡†æ¶
æ‰€æœ‰é¢˜å‹æ ‡å‡†åŒ–å™¨çš„åŸºç±»
"""

import os
import json
import google.generativeai as genai
from typing import List, Tuple, Dict, Optional
from datetime import datetime
from abc import ABC, abstractmethod


class QuestionStandardizerBase(ABC):
    """é¢˜ç›®æ ‡å‡†åŒ–å™¨åŸºç±»"""
    
    def __init__(self, api_key: str, api_base: str = "https://generativelanguage.googleapis.com/v1beta", model: str = "gemini-2.5-pro"):
        """
        åˆå§‹åŒ–æ ‡å‡†åŒ–å™¨
        
        Args:
            api_key: Gemini APIå¯†é’¥
            api_base: APIåŸºç¡€åœ°å€
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(model)
        self.model_name = model
        self.config = self.get_default_config()
    
    def get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "lines_per_chunk": 100,     # æ¯å—è¡Œæ•°
            "overlap_lines": 10,        # é‡å è¡Œæ•°
            "max_retries": 3,           # APIè°ƒç”¨é‡è¯•æ¬¡æ•°
            "preserve_original": True,  # æ˜¯å¦ä¿ç•™åŸæ–‡ä»¶
            "output_format": "markdown" # è¾“å‡ºæ ¼å¼
        }
    
    @abstractmethod
    def get_question_type_name(self) -> str:
        """è·å–é¢˜å‹åç§°"""
        pass
    
    @abstractmethod  
    def get_standard_format(self) -> str:
        """è·å–æ ‡å‡†æ ¼å¼æ¨¡æ¿"""
        pass
    
    @abstractmethod
    def get_format_description(self) -> str:
        """è·å–æ ¼å¼è¯´æ˜"""
        pass
    
    @abstractmethod
    def create_standardization_prompt(self, chunk1: List[str], chunk2: Optional[List[str]] = None) -> str:
        """åˆ›å»ºæ ‡å‡†åŒ–prompt"""
        pass
    
    def chunk_file(self, file_path: str) -> List[Tuple[List[str], Optional[List[str]]]]:
        """
        å°†æ–‡ä»¶æŒ‰è¡Œæ•°åˆ‡åˆ†
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            List[(chunk1_lines, chunk2_lines), ...] æ¯ä¸ªå…ƒç»„åŒ…å«å½“å‰å—å’Œä¸‹ä¸€å—
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            all_lines = f.readlines()
        
        # æå–åŸå§‹æ–‡æœ¬éƒ¨åˆ†ï¼ˆå»æ‰markdownå¤´éƒ¨ï¼‰
        content_start = -1
        for i, line in enumerate(all_lines):
            if line.strip() == "```" and i > 0:  # æ‰¾åˆ°ç¬¬ä¸€ä¸ª```ï¼ˆå†…å®¹å¼€å§‹ï¼‰
                content_start = i + 1
                break
        
        if content_start == -1:
            raise ValueError("æ— æ³•æ‰¾åˆ°markdownæ–‡æœ¬å†…å®¹")
        
        # æå–åˆ°æœ€åä¸€ä¸ª```ä¹‹å‰çš„å†…å®¹
        content_end = len(all_lines)
        for i in range(len(all_lines) - 1, 0, -1):
            if all_lines[i].strip() == "```":
                content_end = i
                break
        
        content_lines = all_lines[content_start:content_end]
        
        chunks = []
        lines_per_chunk = self.config["lines_per_chunk"]
        overlap_lines = self.config["overlap_lines"]
        
        for i in range(0, len(content_lines), lines_per_chunk):
            chunk1_start = i
            chunk1_end = min(i + lines_per_chunk, len(content_lines))
            chunk1 = content_lines[chunk1_start:chunk1_end]
            
            # è·å–ä¸‹ä¸€å—çš„å¼€å§‹éƒ¨åˆ†ä½œä¸ºå‚è€ƒï¼ˆé˜²æ­¢é¢˜ç›®è¢«æˆªæ–­ï¼‰
            chunk2 = None
            if chunk1_end < len(content_lines):
                chunk2_end = min(chunk1_end + lines_per_chunk, len(content_lines))
                chunk2 = content_lines[chunk1_end:chunk2_end]
            
            chunks.append((chunk1, chunk2))
        
        return chunks
    
    def call_ai_standardization(self, prompt: str) -> Optional[str]:
        """
        è°ƒç”¨AIè¿›è¡Œæ ‡å‡†åŒ–
        
        Args:
            prompt: æ ‡å‡†åŒ–prompt
            
        Returns:
            æ ‡å‡†åŒ–ç»“æœæˆ–Noneï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        for attempt in range(self.config["max_retries"]):
            try:
                response = self.model.generate_content(prompt)
                
                # æ›´è¯¦ç»†çš„å“åº”å¤„ç†
                content = None
                if hasattr(response, 'text') and response.text:
                    content = response.text
                elif hasattr(response, 'candidates') and response.candidates:
                    candidate = response.candidates[0]
                    
                    # æ£€æŸ¥finish_reason
                    if hasattr(candidate, 'finish_reason'):
                        finish_reason = candidate.finish_reason
                        print(f"ğŸ“Š APIå“åº”çŠ¶æ€: finish_reason={finish_reason}")
                        
                        if finish_reason == 3:  # SAFETY
                            print(f"âš ï¸ å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢ï¼Œå°è¯•ä¿®æ”¹prompt")
                            # å¦‚æœæ˜¯å®‰å…¨é—®é¢˜ï¼Œå°è¯•ä¿®æ”¹prompté‡è¯•
                            modified_prompt = f"Please help with the following task in a professional manner:\n{prompt}"
                            try:
                                retry_response = self.model.generate_content(modified_prompt)
                                if hasattr(retry_response, 'text') and retry_response.text:
                                    content = retry_response.text
                            except:
                                pass
                        elif finish_reason == 4:  # RECITATION
                            print(f"âš ï¸ å†…å®¹è¢«è®¤ä¸ºæ˜¯è®­ç»ƒæ•°æ®é‡å¤ï¼Œå°è¯•é‡æ–°è¡¨è¿°")
                        elif finish_reason == 1:  # STOP
                            if hasattr(candidate, 'content') and candidate.content and candidate.content.parts:
                                content = candidate.content.parts[0].text
                            else:
                                print(f"âš ï¸ æ¨¡å‹åœæ­¢ä½†æ— å†…å®¹è¾“å‡ºï¼Œå¯èƒ½promptè¿‡äºç®€å•æˆ–è§¦å‘äº†é™åˆ¶")
                
                if content and content.strip():
                    return content
                else:
                    print(f"âŒ ç¬¬{attempt + 1}æ¬¡å°è¯•ï¼šæœªè·å–åˆ°æœ‰æ•ˆå“åº”")
                
            except Exception as e:
                print(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.config['max_retries']}): {e}")
                if attempt == self.config["max_retries"] - 1:
                    return None
        
        return None
    
    def parse_standardized_result(self, ai_response: str) -> List[str]:
        """
        è§£æAIè¿”å›çš„æ ‡å‡†åŒ–ç»“æœ
        
        Args:
            ai_response: AIè¿”å›çš„æ–‡æœ¬
            
        Returns:
            æ ‡å‡†åŒ–åçš„é¢˜ç›®åˆ—è¡¨
        """
        if not ai_response:
            return []
        
        # æŒ‰åˆ†éš”ç¬¦åˆ†å‰²é¢˜ç›®
        separator = "=== é¢˜ç›®åˆ†éš”ç¬¦ ==="
        questions = ai_response.split(separator)
        
        # æ¸…ç†å’Œè¿‡æ»¤
        cleaned_questions = []
        for q in questions:
            q = q.strip()
            if q and len(q) > 50:  # è¿‡æ»¤è¿‡çŸ­çš„å†…å®¹
                cleaned_questions.append(q)
        
        return cleaned_questions
    
    def save_original_chunk(self, chunk_index: int, chunk1: List[str], chunk2: Optional[List[str]], output_dir: str):
        """
        ä¿å­˜åŸå§‹åˆ†å—æ–‡ä»¶ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
        
        Args:
            chunk_index: chunkç´¢å¼•
            chunk1: ç¬¬ä¸€ä¸ªchunkçš„å†…å®¹ï¼ˆä¸»è¦å¤„ç†å†…å®¹ï¼‰
            chunk2: ç¬¬äºŒä¸ªchunkçš„å†…å®¹ï¼ˆä»…ç”¨äºé˜²æˆªæ–­ï¼Œä¸ä¿å­˜åˆ°åŸå§‹æ–‡ä»¶ä¸­ï¼‰
            output_dir: è¾“å‡ºç›®å½•
        """
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # ä¿å­˜åŸå§‹chunkæ–‡ä»¶ï¼ˆåªä¿å­˜å¯¹åº”åˆ†å—çš„å†…å®¹ï¼‰
        chunk_file = os.path.join(output_dir, f"original_chunk_{chunk_index:03d}.md")
        with open(chunk_file, 'w', encoding='utf-8') as f:
            f.write(f"# åŸå§‹ Chunk {chunk_index}\n\n")
            f.write(f"## ç”Ÿæˆæ—¶é—´\n{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"## åˆ†å—å†…å®¹\n\n")
            f.write(''.join(chunk1))
        
        print(f"ğŸ’¾ åŸå§‹ Chunk {chunk_index} å·²ä¿å­˜åˆ°: {chunk_file}")

    def save_chunk_results(self, chunk_index: int, questions: List[str], output_dir: str):
        """
        ä¿å­˜å•ä¸ªchunkçš„æ ‡å‡†åŒ–ç»“æœ
        
        Args:
            chunk_index: chunkç´¢å¼•
            questions: æ ‡å‡†åŒ–åçš„é¢˜ç›®åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
        """
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # ä¿å­˜ä¸ºmarkdownæ–‡ä»¶
        chunk_file = os.path.join(output_dir, f"standardized_chunk_{chunk_index:03d}.md")
        
        with open(chunk_file, 'w', encoding='utf-8') as f:
            f.write(f"# {self.get_question_type_name()} - Chunk {chunk_index}\n\n")
            f.write(f"## æ ‡å‡†åŒ–æ—¶é—´\n{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"## é¢˜ç›®æ•°é‡\n{len(questions)}\n\n")
            f.write(f"## æ ‡å‡†åŒ–é¢˜ç›®\n\n")
            
            for i, question in enumerate(questions, 1):
                f.write(f"### é¢˜ç›® {i}\n\n")
                f.write(f"```\n{question}\n```\n\n")
        
        print(f"âœ… Chunk {chunk_index}: ä¿å­˜ {len(questions)} é“é¢˜ç›®åˆ° {chunk_file}")
    
    def generate_summary_report(self, total_chunks: int, total_questions: int, output_dir: str):
        """
        ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        
        Args:
            total_chunks: æ€»chunkæ•°
            total_questions: æ€»é¢˜ç›®æ•°
            output_dir: è¾“å‡ºç›®å½•
        """
        report_file = os.path.join(output_dir, "standardization_report.md")
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# {self.get_question_type_name()} æ ‡å‡†åŒ–æŠ¥å‘Š\n\n")
            f.write(f"## å¤„ç†æ¦‚å†µ\n")
            f.write(f"- å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"- é¢˜ç›®ç±»å‹: {self.get_question_type_name()}\n")
            f.write(f"- æ€»chunkæ•°: {total_chunks}\n")
            f.write(f"- æ ‡å‡†åŒ–é¢˜ç›®æ€»æ•°: {total_questions}\n")
            f.write(f"- å¹³å‡æ¯chunké¢˜ç›®æ•°: {total_questions/total_chunks if total_chunks > 0 else 0:.1f}\n\n")
            
            f.write(f"## æ ‡å‡†æ ¼å¼\n")
            f.write(f"```\n{self.get_standard_format()}\n```\n\n")
            
            f.write(f"## æ ¼å¼è¯´æ˜\n")
            f.write(f"{self.get_format_description()}\n\n")
            
            f.write(f"## æ–‡ä»¶ç»“æ„\n")
            f.write(f"```\n")
            f.write(f"{os.path.basename(output_dir)}/\n")
            f.write(f"â”œâ”€â”€ original_backup.md           # åŸæ–‡ä»¶å¤‡ä»½\n")
            f.write(f"â”œâ”€â”€ standardization_report.md   # æœ¬æŠ¥å‘Š\n")
            for i in range(total_chunks):
                f.write(f"â”œâ”€â”€ original_chunk_{i+1:03d}.md      # ç¬¬{i+1}ä¸ªchunkçš„åŸå§‹å†…å®¹ï¼ˆç”¨äºå¯¹æ¯”ï¼‰\n")
            for i in range(total_chunks):
                f.write(f"â”œâ”€â”€ standardized_chunk_{i+1:03d}.md  # ç¬¬{i+1}ä¸ªchunkçš„æ ‡å‡†åŒ–ç»“æœ\n")
            f.write(f"â””â”€â”€ quality_stats.json          # è´¨é‡ç»Ÿè®¡æ•°æ®\n")
            f.write(f"```\n")
        
        print(f"ğŸ“Š æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    def standardize_file(self, input_file: str, output_dir: str = None) -> Dict:
        """
        æ ‡å‡†åŒ–å•ä¸ªé¢˜å‹æ–‡ä»¶çš„ä¸»è¦æ–¹æ³•
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™è‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        if output_dir is None:
            base_dir = os.path.dirname(input_file)
            output_dir = os.path.join(base_dir, f"{self.get_question_type_name()}_standardized")
        
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        print(f"ğŸš€ å¼€å§‹æ ‡å‡†åŒ– {self.get_question_type_name()}")
        print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {input_file}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        
        # å¤‡ä»½åŸæ–‡ä»¶
        if self.config["preserve_original"]:
            backup_file = os.path.join(output_dir, "original_backup.md")
            os.system(f'cp "{input_file}" "{backup_file}"')
            print(f"ğŸ’¾ åŸæ–‡ä»¶å·²å¤‡ä»½åˆ°: {backup_file}")
        
        # åˆ‡åˆ†æ–‡ä»¶
        print(f"ğŸ”ª æ­£åœ¨åˆ‡åˆ†æ–‡ä»¶...")
        chunks = self.chunk_file(input_file)
        print(f"ğŸ“ æ–‡ä»¶å·²åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªå—")
        
        # ä¿å­˜åŸå§‹åˆ†å—æ–‡ä»¶ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
        if self.config["preserve_original"]:
            print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜åŸå§‹åˆ†å—æ–‡ä»¶...")
            for i, (chunk1, chunk2) in enumerate(chunks, 1):
                self.save_original_chunk(i, chunk1, chunk2, output_dir)
        
        # æ ‡å‡†åŒ–æ¯ä¸ªchunk
        total_questions = 0
        for i, (chunk1, chunk2) in enumerate(chunks, 1):
            print(f"\nğŸ”„ å¤„ç† Chunk {i}/{len(chunks)}")
            
            # åˆ›å»ºæ ‡å‡†åŒ–prompt
            prompt = self.create_standardization_prompt(chunk1, chunk2)
            
            # è°ƒç”¨AIæ ‡å‡†åŒ–
            ai_response = self.call_ai_standardization(prompt)
            if ai_response is None:
                print(f"âŒ Chunk {i} AIè°ƒç”¨å¤±è´¥ï¼Œè·³è¿‡")
                continue
            
            # è§£æç»“æœ
            questions = self.parse_standardized_result(ai_response)
            
            # ä¿å­˜ç»“æœ
            self.save_chunk_results(i, questions, output_dir)
            total_questions += len(questions)
        
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        self.generate_summary_report(len(chunks), total_questions, output_dir)
        
        # ä¿å­˜è´¨é‡ç»Ÿè®¡
        quality_stats = {
            "question_type": self.get_question_type_name(),
            "total_chunks": len(chunks),
            "total_questions": total_questions,
            "processing_time": datetime.now().isoformat(),
            "config": self.config
        }
        
        stats_file = os.path.join(output_dir, "quality_stats.json")
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(quality_stats, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ‰ {self.get_question_type_name()} æ ‡å‡†åŒ–å®Œæˆï¼")
        print(f"ğŸ“Š æ€»è®¡å¤„ç†: {len(chunks)} ä¸ªå—, {total_questions} é“é¢˜ç›®")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
        
        return quality_stats
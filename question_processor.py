"""
é¢˜åº“å¤„ç†å™¨ - ä¸»è¦æ¨¡å—
ç”¨äºä»PDFæ–‡æ¡£ä¸­æå–é¢˜ç›®å¹¶è½¬æ¢ä¸ºç»“æ„åŒ–çš„Excelæ–‡ä»¶
"""

import fitz  # PyMuPDF
import openpyxl
import json
import re
import os
import tempfile
import datetime
from typing import List, Dict, Optional, Tuple
from tqdm import tqdm


class QuestionProcessor:
    """é¢˜åº“å¤„ç†å™¨ä¸»ç±»ï¼ˆä»…ä¿ç•™PDFè§£æä¸é¢˜å‹æ‹†åˆ†å·¥å…·æ–¹æ³•ï¼ŒAIæµç¨‹å·²ç§»é™¤ï¼‰"""
    
    # å®šä¹‰é¢˜å‹æ˜ å°„
    QUESTION_TYPE_MAPPING = {
        "å•é€‰é¢˜": {"name": "single_choice", "pattern": r"äºŒã€å•é€‰é¢˜ï¼š.*[ï¼ˆ(](\d+).*é¢˜[ï¼‰)]"},
        "å¤šé€‰é¢˜": {"name": "multiple_choice", "pattern": r"ä¸‰ã€å¤šé€‰é¢˜ï¼š.*[ï¼ˆ(](\d+).*é¢˜[ï¼‰)]"},
        "åˆ¤æ–­é¢˜": {"name": "judgment", "pattern": r"å››ã€åˆ¤æ–­é¢˜ï¼š.*[ï¼ˆ(](\d+).*é¢˜[ï¼‰)]"},
        "ç®€ç­”é¢˜": {"name": "short_answer", "pattern": r"äº”ã€ç®€ç­”é¢˜.*[ï¼ˆ(](\d+).*é¢˜[ï¼‰)]"},
        "è®ºè¿°é¢˜": {"name": "essay", "pattern": r"å…­ã€è®ºè¿°é¢˜.*[ï¼ˆ(](\d+).*é¢˜[ï¼‰)]"},
        "æ¡ˆä¾‹åˆ†æé¢˜": {"name": "case_analysis", "pattern": r"ä¸ƒã€æ¡ˆä¾‹åˆ†æé¢˜ï¼š.*[ï¼ˆ(](\d+).*é¢˜[ï¼‰)]"}
    }
    
    def __init__(self):
        """åˆå§‹åŒ–ï¼ˆä¸å†ä¾èµ– Geminiï¼‰"""
        pass
    
    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """ä»PDFæ–‡ä»¶ä¸­æå–æ‰€æœ‰æ–‡æœ¬"""
        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        
        try:
            doc = fitz.open(pdf_path)
            full_text = ""
            
            for page in doc:
                full_text += page.get_text() + "\n"
            
            doc.close()
            return full_text
            
        except Exception as e:
            raise Exception(f"PDFå¤„ç†é”™è¯¯: {e}") from e
    
    def split_text_by_question_types(self, text: str, output_dir: str) -> Dict[str, Dict]:
        """
        æŒ‰é¢˜å‹æ‹†åˆ†æ–‡æœ¬å¹¶ä¿å­˜åˆ°å­æ–‡ä»¶
        
        Args:
            text: å®Œæ•´çš„PDFæ–‡æœ¬
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            Dict: åŒ…å«å„é¢˜å‹ä¿¡æ¯çš„å­—å…¸ {é¢˜å‹å: {"file_path": è·¯å¾„, "text": æ–‡æœ¬, "count": é¢„æœŸé¢˜æ•°}}
        """
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        lines = text.split('\n')
        question_type_sections = {}
        
        # æ‰¾åˆ°å„é¢˜å‹çš„èµ·å§‹ä½ç½®
        section_positions = []
        for i, line in enumerate(lines):
            line = line.strip()
            for type_name, type_info in self.QUESTION_TYPE_MAPPING.items():
                if re.search(type_info["pattern"], line):
                    # æå–é¢„æœŸé¢˜æ•°
                    count_match = re.search(r'[ï¼ˆ(](\d+).*é¢˜[ï¼‰)]', line)
                    expected_count = int(count_match.group(1)) if count_match else 0
                    
                    section_positions.append({
                        "type_name": type_name,
                        "type_info": type_info,
                        "line_index": i,
                        "expected_count": expected_count,
                        "section_line": line
                    })
                    print(f"æ‰¾åˆ°é¢˜å‹: {type_name}ï¼Œé¢„æœŸé¢˜æ•°: {expected_count}")
                    break
        
        # æŒ‰è¡Œå·æ’åº
        section_positions.sort(key=lambda x: x["line_index"])
        
        # æå–å„é¢˜å‹çš„æ–‡æœ¬å†…å®¹
        for i, section in enumerate(section_positions):
            type_name = section["type_name"]
            type_info = section["type_info"]
            start_line = section["line_index"]
            expected_count = section["expected_count"]
            
            # ç¡®å®šç»“æŸä½ç½®ï¼ˆä¸‹ä¸€ä¸ªé¢˜å‹çš„å¼€å§‹æˆ–æ–‡æ¡£ç»“æŸï¼‰
            if i + 1 < len(section_positions):
                end_line = section_positions[i + 1]["line_index"]
            else:
                end_line = len(lines)
            
            # æå–è¯¥é¢˜å‹çš„æ–‡æœ¬
            section_text = '\n'.join(lines[start_line:end_line])
            
            # ä¿å­˜åˆ°markdownæ–‡ä»¶
            filename = f"{type_info['name']}.md"
            file_path = os.path.join(output_dir, filename)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(f"# {type_name} ({expected_count}é¢˜)\n\n")
                f.write(f"## æå–æ—¶é—´\n{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write(f"## é¢„æœŸé¢˜æ•°\n{expected_count}\n\n")
                f.write(f"## åŸå§‹æ–‡æœ¬\n\n```\n{section_text}\n```\n")
            
            question_type_sections[type_name] = {
                "file_path": file_path,
                "text": section_text,
                "expected_count": expected_count,
                "type_info": type_info
            }
            
            print(f"âœ… ä¿å­˜ {type_name} åˆ°: {file_path}")
        
        return question_type_sections
    
    def split_text_into_questions(self, text: str) -> List[str]:
        """å°†é•¿æ–‡æœ¬åˆ†å‰²æˆç‹¬ç«‹çš„é¢˜ç›®å— - æ”¹è¿›ç‰ˆæœ¬æ”¯æŒå¤šä¸ªsectionçš„é‡å¤ç¼–å·"""
        if not text or not text.strip():
            return []
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ‰¾åˆ°æ‰€æœ‰é¢˜ç›®ç¼–å·ä½ç½®
        question_pattern = r'\n\s*(\d+)[.ï¼ã€]\s*[ï¼ˆ(]?'
        
        # åˆ†å‰²æ–‡æœ¬ï¼Œä½†ä¿ç•™åˆ†å‰²ç¬¦
        parts = re.split(question_pattern, text)
        
        if len(parts) <= 1:
            return []
        
        questions = []
        
        # é‡æ–°ç»„è£…é¢˜ç›®ï¼Œå°†ç¼–å·å’Œå†…å®¹åˆå¹¶
        for i in range(1, len(parts), 2):
            if i + 1 < len(parts):
                question_num = parts[i]
                question_content = parts[i + 1]
                
                # é‡æ–°æ„å»ºå®Œæ•´çš„é¢˜ç›®æ–‡æœ¬
                full_question = f"{question_num}. {question_content.strip()}"
                
                # è¿‡æ»¤æ‰è¿‡çŸ­çš„æ–‡æœ¬å—ï¼ˆå¯èƒ½æ˜¯ç« èŠ‚æ ‡é¢˜ç­‰ï¼‰
                if len(full_question) > 20:
                    questions.append(full_question)
        
        # æ—§çš„éAIè¡¥æ•‘é€»è¾‘å·²ç§»é™¤
        
        return questions
    
    def process_single_question_type(self, question_type_file: str, output_dir: str = None) -> List[Dict]:
        """
        å¤„ç†å•ä¸ªé¢˜å‹æ–‡ä»¶
        
        Args:
            question_type_file: é¢˜å‹æ–‡ä»¶è·¯å¾„ï¼ˆmarkdownæ ¼å¼ï¼‰
            output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤ç›®å½•
            
        Returns:
            List[Dict]: å¤„ç†åçš„é¢˜ç›®æ•°æ®åˆ—è¡¨
        """
        if not os.path.exists(question_type_file):
            raise FileNotFoundError(f"é¢˜å‹æ–‡ä»¶ä¸å­˜åœ¨: {question_type_file}")
        
        # è¯»å–é¢˜å‹æ–‡ä»¶
        with open(question_type_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå–é¢˜å‹åç§°å’ŒåŸå§‹æ–‡æœ¬
        type_name = ""
        if "# " in content:
            type_line = content.split('\n')[0]
            type_name = type_line.replace('# ', '').split(' (')[0]
        
        # æå–åŸå§‹æ–‡æœ¬éƒ¨åˆ†
        text_start = content.find("```\n") + 4
        text_end = content.rfind("\n```")
        if text_start > 3 and text_end > text_start:
            section_text = content[text_start:text_end]
        else:
            raise ValueError("æ— æ³•ä»é¢˜å‹æ–‡ä»¶ä¸­æå–åŸå§‹æ–‡æœ¬")
        
        print(f"å¼€å§‹å¤„ç†é¢˜å‹: {type_name}")
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        if output_dir is None:
            base_dir = os.path.dirname(question_type_file)
            output_dir = os.path.join(base_dir, f"{type_name}_questions")
        
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        print(f"é¢˜ç›®è¾“å‡ºç›®å½•: {output_dir}")
        
        # åˆ†å‰²æˆç‹¬ç«‹é¢˜ç›®
        questions = self.split_text_into_questions(section_text)
        print(f"ä» {type_name} ä¸­æå–åˆ° {len(questions)} é“é¢˜ç›®")
        
        # ä¿å­˜æ¯é“é¢˜ç›®åˆ°markdownæ–‡ä»¶
        saved_count = 0
        for i, question_text in enumerate(questions, 1):
            markdown_path = self.save_question_to_markdown(i, question_text, output_dir)
            if markdown_path:
                saved_count += 1
        
        print(f"å·²ä¿å­˜ {saved_count} é“é¢˜ç›®çš„markdownæ–‡ä»¶åˆ°: {output_dir}")
        
        # ä½¿ç”¨AIå¤„ç†æ¯é“é¢˜ç›®
        print(f"æ­£åœ¨ä½¿ç”¨AIå¤„ç† {type_name} é¢˜ç›®...")
        processed_questions = []
        
        for i, question_text in enumerate(tqdm(questions, desc=f"å¤„ç†{type_name}")):
            try:
                structured_data = self.get_structured_data_from_ai(question_text)
                if structured_data:
                    # æ·»åŠ é¢˜ç›®åºå·å’Œç±»å‹ä¿¡æ¯
                    structured_data['source_index'] = i + 1
                    structured_data['source_type'] = type_name
                    structured_data['markdown_file'] = f"question_{i+1:04d}.md"
                    processed_questions.append(structured_data)
                else:
                    print(f"è­¦å‘Šï¼šç¬¬{i+1}é“{type_name}é¢˜ç›®å¤„ç†å¤±è´¥ï¼Œè·³è¿‡")
            except Exception as e:
                print(f"è­¦å‘Šï¼šç¬¬{i+1}é“{type_name}é¢˜ç›®å¤„ç†å‡ºé”™: {e}")
                continue
        
        print(f"AIå¤„ç†å®Œæˆï¼ŒæˆåŠŸå¤„ç† {len(processed_questions)} é“{type_name}é¢˜ç›®")
        
        # ä¿å­˜åˆ°å¯¹åº”çš„Excelæ–‡ä»¶
        excel_path = os.path.join(output_dir, f"{type_name}_processed.xlsx")
        self.save_to_excel(processed_questions, excel_path)
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {excel_path}")
        
        return processed_questions
    
    def split_questions_only(self, question_type_file: str, output_dir: str = None) -> int:
        """
        ä»…å°†é¢˜å‹æ–‡ä»¶æ‹†åˆ†ä¸ºç‹¬ç«‹çš„é¢˜ç›®æ–‡ä»¶ï¼Œä¸è¿›è¡ŒAIå¤„ç†
        
        Args:
            question_type_file: é¢˜å‹æ–‡ä»¶è·¯å¾„ï¼ˆmarkdownæ ¼å¼ï¼‰
            output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤ç›®å½•
            
        Returns:
            int: æ‹†åˆ†å‡ºçš„é¢˜ç›®æ•°é‡
        """
        if not os.path.exists(question_type_file):
            raise FileNotFoundError(f"é¢˜å‹æ–‡ä»¶ä¸å­˜åœ¨: {question_type_file}")
        
        # è¯»å–é¢˜å‹æ–‡ä»¶
        with open(question_type_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå–é¢˜å‹åç§°å’Œé¢„æœŸé¢˜æ•°
        type_name = ""
        expected_count = 0
        if "# " in content:
            type_line = content.split('\n')[0]
            type_name = type_line.replace('# ', '').split(' (')[0]
            # æå–é¢„æœŸé¢˜æ•°
            if '(' in type_line and 'é¢˜)' in type_line:
                count_part = type_line.split('(')[1].split('é¢˜)')[0]
                try:
                    expected_count = int(count_part)
                except ValueError:
                    expected_count = 0
        
        # æå–åŸå§‹æ–‡æœ¬éƒ¨åˆ†
        text_start = content.find("```\n") + 4
        text_end = content.rfind("\n```")
        if text_start > 3 and text_end > text_start:
            section_text = content[text_start:text_end]
        else:
            raise ValueError("æ— æ³•ä»é¢˜å‹æ–‡ä»¶ä¸­æå–åŸå§‹æ–‡æœ¬")
        
        print(f"å¼€å§‹æ‹†åˆ†é¢˜å‹: {type_name}")
        print(f"é¢„æœŸé¢˜æ•°: {expected_count}")
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        if output_dir is None:
            base_dir = os.path.dirname(question_type_file)
            output_dir = os.path.join(base_dir, f"{type_name}_questions")
        
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        print(f"é¢˜ç›®è¾“å‡ºç›®å½•: {output_dir}")
        
        # åˆ†å‰²æˆç‹¬ç«‹é¢˜ç›®
        questions = self.split_text_into_questions(section_text)
        actual_count = len(questions)
        print(f"ä» {type_name} ä¸­æå–åˆ° {actual_count} é“é¢˜ç›® (é¢„æœŸ: {expected_count})")
        
        # ä¿å­˜æ¯é“é¢˜ç›®åˆ°markdownæ–‡ä»¶
        saved_count = 0
        for i, question_text in enumerate(questions, 1):
            markdown_path = self.save_question_to_markdown(i, question_text, output_dir)
            if markdown_path:
                saved_count += 1
        
        print(f"âœ… å·²ä¿å­˜ {saved_count} é“é¢˜ç›®çš„markdownæ–‡ä»¶åˆ°: {output_dir}")
        
        # ç”Ÿæˆæ‹†åˆ†ç»Ÿè®¡ä¿¡æ¯
        stats_file = os.path.join(output_dir, "split_stats.md")
        with open(stats_file, 'w', encoding='utf-8') as f:
            f.write(f"# {type_name} æ‹†åˆ†ç»Ÿè®¡\n\n")
            f.write(f"## åŸºæœ¬ä¿¡æ¯\n")
            f.write(f"- é¢˜å‹: {type_name}\n")
            f.write(f"- é¢„æœŸé¢˜æ•°: {expected_count}\n")
            f.write(f"- å®é™…æå–: {actual_count} é“é¢˜ç›®\n")
            f.write(f"- ä¿å­˜æˆåŠŸ: {saved_count} ä¸ªæ–‡ä»¶\n")
            f.write(f"- æ‹†åˆ†æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"## æå–ç‡\n")
            if expected_count > 0:
                extraction_rate = (actual_count / expected_count) * 100
                f.write(f"- æå–ç‡: {extraction_rate:.1f}% ({actual_count}/{expected_count})\n")
            else:
                f.write(f"- æå–ç‡: æ— æ³•è®¡ç®—ï¼ˆé¢„æœŸé¢˜æ•°ä¸º0ï¼‰\n")
            
            if actual_count != expected_count:
                f.write(f"\n## âš ï¸ æ³¨æ„äº‹é¡¹\n")
                if actual_count < expected_count:
                    f.write(f"- å®é™…æå–æ•°é‡å°‘äºé¢„æœŸï¼Œå¯èƒ½å­˜åœ¨é¢˜ç›®æ ¼å¼è¯†åˆ«é—®é¢˜\n")
                    f.write(f"- å»ºè®®æ£€æŸ¥åŸå§‹æ–‡æœ¬æ ¼å¼ï¼Œä¼˜åŒ–é¢˜ç›®åˆ†å‰²ç®—æ³•\n")
                else:
                    f.write(f"- å®é™…æå–æ•°é‡å¤šäºé¢„æœŸï¼Œå¯èƒ½å­˜åœ¨é‡å¤æˆ–è¯¯è¯†åˆ«\n")
                    f.write(f"- å»ºè®®æŠ½æ ·æ£€æŸ¥é¢˜ç›®å†…å®¹çš„æ­£ç¡®æ€§\n")
            
            f.write(f"\n## æ–‡ä»¶åˆ—è¡¨\n")
            for i in range(1, saved_count + 1):
                f.write(f"- question_{i:04d}.md\n")
        
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_file}")
        return actual_count
    
    def save_question_to_markdown(self, question_index: int, question_text: str, temp_dir: str) -> str:
        """å°†å•ä¸ªé¢˜ç›®ä¿å­˜ä¸ºmarkdownæ–‡ä»¶ç”¨äºè¿½æº¯"""
        if not os.path.exists(temp_dir):
            os.makedirs(temp_dir)
        
        # åˆ›å»ºæ–‡ä»¶åï¼Œä½¿ç”¨4ä½æ•°è¡¥é›¶
        filename = f"question_{question_index:04d}.md"
        filepath = os.path.join(temp_dir, filename)
        
        # å‡†å¤‡markdownå†…å®¹
        markdown_content = f"""# é¢˜ç›® {question_index}

## åŸå§‹æ–‡æœ¬

```
{question_text}
```

## æå–æ—¶é—´
{__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ–‡æœ¬é•¿åº¦
{len(question_text)} å­—ç¬¦

---
"""
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
            return filepath
        except Exception as e:
            print(f"è­¦å‘Šï¼šæ— æ³•ä¿å­˜é¢˜ç›®{question_index}çš„markdownæ–‡ä»¶: {e}")
            return ""
    
    def get_structured_data_from_ai(self, question_text: str) -> Optional[Dict]:
        """è°ƒç”¨AIä»å•ä¸ªé¢˜ç›®æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯"""
        if not question_text or not question_text.strip():
            return None
        system_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¢˜ç›®è§£æåŠ©æ‰‹ã€‚è¯·ä»ç»™å®šçš„é¢˜ç›®æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ã€‚

è¿”å›æ ¼å¼è¦æ±‚:
{
    "question_type": "é¢˜ç›®ç±»å‹ï¼ˆå•é€‰/å¤šé€‰/åˆ¤æ–­/å¡«ç©º/ç®€ç­”ï¼‰",
    "difficulty": "éš¾åº¦æ ‡è®°ï¼ˆå¦‚æœæœ‰ï¼‰",
    "question_stem": "é¢˜ç›®ä¸»å¹²å†…å®¹",
    "options": ["é€‰é¡¹åˆ—è¡¨ï¼ˆå¦‚æœæœ‰ï¼‰"],
    "answer": "å‚è€ƒç­”æ¡ˆ",
    "explanation": "è§£æå†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰"
}

æ³¨æ„:
1. ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°JSONæ ¼å¼è¿”å›
2. å¦‚æœæ²¡æœ‰é€‰é¡¹ï¼Œoptionså­—æ®µè¿”å›ç©ºæ•°ç»„[]
3. å¦‚æœæ²¡æœ‰è§£æï¼Œexplanationå­—æ®µè¿”å›ç©ºå­—ç¬¦ä¸²""
4. å¦‚æœæ²¡æœ‰éš¾åº¦æ ‡è®°ï¼Œdifficultyå­—æ®µè¿”å›ç©ºå­—ç¬¦ä¸²""
5. å‡†ç¡®è¯†åˆ«é¢˜ç›®ç±»å‹ï¼šå•é€‰ã€å¤šé€‰ã€åˆ¤æ–­ã€å¡«ç©ºã€ç®€ç­”
"""

        user_prompt = f"è¯·è§£æä»¥ä¸‹é¢˜ç›®ï¼š\n{question_text}"
        
        try:
            response = self.model.generate_content(
                f"{system_prompt}\n\n{user_prompt}"
            )
            
            # å®‰å…¨åœ°è·å–å“åº”æ–‡æœ¬
            content = None
            if hasattr(response, 'text') and response.text:
                content = response.text
            elif hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                if hasattr(candidate, 'content') and candidate.content.parts:
                    content = candidate.content.parts[0].text
            
            if not content:
                return None
                
            result = json.loads(content)
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ["question_type", "difficulty", "question_stem", "options", "answer", "explanation"]
            for field in required_fields:
                if field not in result:
                    result[field] = "" if field != "options" else []
            
            return result
            
        except json.JSONDecodeError:
            # JSONè§£æå¤±è´¥
            return None
        except Exception as e:
            # APIè°ƒç”¨æˆ–å…¶ä»–é”™è¯¯
            return None
    
    def save_to_excel(self, questions_data: List[Dict], output_path: str) -> None:
        """å°†ç»“æ„åŒ–æ•°æ®ä¿å­˜åˆ°Excelæ–‡ä»¶"""
        if not questions_data and not os.path.exists(output_path):
            # å¦‚æœæ²¡æœ‰æ•°æ®ä¸”ä¸æ˜¯åŸºäºç°æœ‰æ¨¡æ¿ï¼Œåˆ›å»ºç©ºçš„Excelæ–‡ä»¶
            wb = openpyxl.Workbook()
            ws = wb.active
            ws.title = "é¢˜åº“æ•°æ®"
            
            # è®¾ç½®è¡¨å¤´
            headers = ["åºå·", "é¢˜å‹", "éš¾åº¦", "é¢˜ç›®", "é€‰é¡¹A", "é€‰é¡¹B", "é€‰é¡¹C", "é€‰é¡¹D", "é€‰é¡¹E", "ç­”æ¡ˆ", "è§£æ"]
            for col, header in enumerate(headers, 1):
                ws.cell(row=1, column=col, value=header)
            
            try:
                wb.save(output_path)
            except Exception as e:
                raise Exception(f"Excelæ–‡ä»¶ä¿å­˜å¤±è´¥: {e}") from e
            return
        
        # å¦‚æœè¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ï¼ŒåŠ è½½ç°æœ‰æ–‡ä»¶ï¼ˆä½œä¸ºæ¨¡æ¿ï¼‰
        if os.path.exists(output_path):
            try:
                wb = openpyxl.load_workbook(output_path)
            except Exception as e:
                # å¦‚æœåŠ è½½å¤±è´¥ï¼Œåˆ›å»ºæ–°çš„å·¥ä½œç°¿
                wb = openpyxl.Workbook()
        else:
            wb = openpyxl.Workbook()
        
        ws = wb.active
        if ws.title == "Sheet":
            ws.title = "é¢˜åº“æ•°æ®"
        
        # è®¾ç½®è¡¨å¤´ï¼ˆå¦‚æœæ˜¯æ–°å»ºçš„å·¥ä½œç°¿ï¼‰
        if ws.max_row == 1 and not ws.cell(row=1, column=1).value:
            headers = ["åºå·", "é¢˜å‹", "éš¾åº¦", "é¢˜ç›®", "é€‰é¡¹A", "é€‰é¡¹B", "é€‰é¡¹C", "é€‰é¡¹D", "é€‰é¡¹E", "ç­”æ¡ˆ", "è§£æ"]
            for col, header in enumerate(headers, 1):
                ws.cell(row=1, column=col, value=header)
        
        # æ‰¾åˆ°æ•°æ®å¼€å§‹è¡Œï¼ˆè¡¨å¤´åçš„ç¬¬ä¸€ä¸ªç©ºè¡Œï¼‰
        start_row = ws.max_row + 1 if ws.max_row > 1 else 2
        
        # é€è¡Œå†™å…¥é¢˜ç›®æ•°æ®
        for idx, question in enumerate(questions_data):
            row = start_row + idx
            
            # åºå·
            ws.cell(row=row, column=1, value=idx + 1)
            
            # é¢˜å‹
            ws.cell(row=row, column=2, value=question.get("question_type", ""))
            
            # éš¾åº¦
            ws.cell(row=row, column=3, value=question.get("difficulty", ""))
            
            # é¢˜ç›®
            ws.cell(row=row, column=4, value=question.get("question_stem", ""))
            
            # é€‰é¡¹ï¼ˆæœ€å¤šæ”¯æŒ5ä¸ªé€‰é¡¹A-Eï¼‰
            options = question.get("options", [])
            for i in range(5):  # é€‰é¡¹A-Eå¯¹åº”åˆ—5-9
                if i < len(options):
                    ws.cell(row=row, column=5+i, value=options[i])
                else:
                    ws.cell(row=row, column=5+i, value="")
            
            # ç­”æ¡ˆ
            ws.cell(row=row, column=10, value=question.get("answer", ""))
            
            # è§£æ
            ws.cell(row=row, column=11, value=question.get("explanation", ""))
        
        # ä¿å­˜æ–‡ä»¶
        try:
            wb.save(output_path)
        except Exception as e:
            raise Exception(f"Excelæ–‡ä»¶ä¿å­˜å¤±è´¥: {e}") from e
    
    def process_questions(self, pdf_path: str, output_path: str, step: str = "full") -> None:
        """
        å®Œæ•´çš„é¢˜ç›®å¤„ç†æµç¨‹ï¼Œæ”¯æŒåˆ†æ­¥éª¤æ‰§è¡Œ
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            step: å¤„ç†æ­¥éª¤ - "split", "split-questions", "process", "full"
        """
        base_name = os.path.splitext(os.path.basename(pdf_path))[0]
        work_dir = f"question_processing_{base_name}"
        
        if not os.path.exists(work_dir):
            os.makedirs(work_dir)
        
        print(f"å¼€å§‹å¤„ç†PDFæ–‡ä»¶: {pdf_path}")
        print(f"å·¥ä½œç›®å½•: {work_dir}")
        print(f"æ‰§è¡Œæ­¥éª¤: {step}")
        
        if step in ["split", "full"]:
            # æ­¥éª¤1: æå–PDFæ–‡æœ¬å¹¶æŒ‰é¢˜å‹æ‹†åˆ†
            print("\n" + "="*50)
            print("æ­¥éª¤1: æå–PDFæ–‡æœ¬å¹¶æŒ‰é¢˜å‹æ‹†åˆ†")
            print("="*50)
            
            full_text = self.extract_text_from_pdf(pdf_path)
            print(f"æå–å®Œæˆï¼Œå…±{len(full_text)}å­—ç¬¦")
            
            # æŒ‰é¢˜å‹æ‹†åˆ†
            type_sections_dir = os.path.join(work_dir, "question_types")
            question_type_sections = self.split_text_by_question_types(full_text, type_sections_dir)
            
            print(f"\nâœ… æŒ‰é¢˜å‹æ‹†åˆ†å®Œæˆï¼Œå…±æ‰¾åˆ° {len(question_type_sections)} ä¸ªé¢˜å‹")
            for type_name, info in question_type_sections.items():
                print(f"  ğŸ“‹ {type_name}: {info['expected_count']} é¢˜ -> {info['file_path']}")
        
        if step in ["split-questions", "full"]:
            # æ­¥éª¤2: å°†å„é¢˜å‹æ–‡ä»¶æ‹†åˆ†ä¸ºç‹¬ç«‹é¢˜ç›®æ–‡ä»¶
            print("\n" + "="*50)
            print("æ­¥éª¤2: å°†é¢˜å‹æ–‡ä»¶æ‹†åˆ†ä¸ºç‹¬ç«‹é¢˜ç›®")
            print("="*50)
            
            type_sections_dir = os.path.join(work_dir, "question_types")
            if not os.path.exists(type_sections_dir):
                raise FileNotFoundError("é¢˜å‹åˆ†ç¦»æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ‰§è¡Œ step='split'")
            
            # æŸ¥æ‰¾æ‰€æœ‰é¢˜å‹æ–‡ä»¶
            type_files = []
            for filename in os.listdir(type_sections_dir):
                if filename.endswith('.md'):
                    type_files.append(os.path.join(type_sections_dir, filename))
            
            if not type_files:
                raise FileNotFoundError("æœªæ‰¾åˆ°é¢˜å‹æ–‡ä»¶ï¼Œè¯·å…ˆæ‰§è¡Œ step='split'")
            
            total_questions = 0
            split_summary = []
            
            # æ‹†åˆ†æ¯ä¸ªé¢˜å‹æ–‡ä»¶
            for type_file in sorted(type_files):
                try:
                    question_count = self.split_questions_only(type_file)
                    total_questions += question_count
                    
                    # è®°å½•æ‹†åˆ†ä¿¡æ¯
                    filename = os.path.basename(type_file)
                    type_name = filename.replace('.md', '').replace('_', ' ').title()
                    split_summary.append({
                        'file': filename,
                        'type': type_name,
                        'count': question_count
                    })
                    
                except Exception as e:
                    print(f"âŒ æ‹†åˆ†é¢˜å‹æ–‡ä»¶ {type_file} æ—¶å‡ºé”™: {e}")
                    continue
            
            print(f"\nâœ… æ‰€æœ‰é¢˜å‹æ‹†åˆ†å®Œæˆï¼Œå…±æ‹†åˆ†å‡º {total_questions} é“ç‹¬ç«‹é¢˜ç›®")
            
            # ç”Ÿæˆæ€»ä½“ç»Ÿè®¡æŠ¥å‘Š
            summary_file = os.path.join(work_dir, "split_summary.md")
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write(f"# é¢˜ç›®æ‹†åˆ†æ€»ç»“æŠ¥å‘Š\n\n")
                f.write(f"## æ€»ä½“ä¿¡æ¯\n")
                f.write(f"- å¤„ç†æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"- æ€»é¢˜ç›®æ•°: {total_questions} é“\n")
                f.write(f"- é¢˜å‹æ•°é‡: {len(split_summary)} ä¸ª\n\n")
                f.write(f"## å„é¢˜å‹è¯¦æƒ…\n")
                
                for info in split_summary:
                    f.write(f"### {info['type']}\n")
                    f.write(f"- æ–‡ä»¶: {info['file']}\n")
                    f.write(f"- é¢˜ç›®æ•°: {info['count']} é“\n")
                    f.write(f"- ç›®å½•: {info['type'].lower().replace(' ', '_')}_questions/\n\n")
                
                f.write(f"## ç›®å½•ç»“æ„\n")
                f.write(f"```\n")
                f.write(f"{work_dir}/\n")
                f.write(f"â”œâ”€â”€ question_types/          # é¢˜å‹åˆ†ç±»æ–‡ä»¶\n")
                for info in split_summary:
                    f.write(f"â”œâ”€â”€ {info['type'].lower().replace(' ', '_')}_questions/  # {info['count']}ä¸ªé¢˜ç›®æ–‡ä»¶\n")
                f.write(f"â””â”€â”€ split_summary.md         # æœ¬æŠ¥å‘Š\n")
                f.write(f"```\n")
            
            print(f"ğŸ“Š æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜åˆ°: {summary_file}")
            print(f"\nğŸ“ å„é¢˜å‹é¢˜ç›®è¯¦æƒ…:")
            for info in split_summary:
                questions_dir = os.path.join(work_dir, f"{info['type'].lower().replace(' ', '_')}_questions")
                print(f"  ğŸ“‚ {info['type']}: {info['count']} é“é¢˜ç›® -> {questions_dir}")
        
        if step in ["process", "full"]:
            # æ­¥éª¤3: AIå¤„ç†å„é¢˜å‹ï¼ˆåŸæœ‰çš„å¤„ç†é€»è¾‘ï¼‰
            print("\n" + "="*50)
            print("æ­¥éª¤3: AIå¤„ç†å„é¢˜å‹é¢˜ç›®")
            print("="*50)
            
            # è¿™é‡Œä¿æŒåŸæœ‰çš„AIå¤„ç†é€»è¾‘
            # æŸ¥æ‰¾å·²ç»æ‹†åˆ†çš„é¢˜ç›®æ–‡ä»¶å¹¶è¿›è¡ŒAIå¤„ç†
            print("â³ AIå¤„ç†åŠŸèƒ½å°†åœ¨ä¸‹ä¸€æ­¥éª¤ä¸­å®ç°...")
            print("ğŸ’¡ å½“å‰æ­¥éª¤å·²å®Œæˆé¢˜ç›®æ‹†åˆ†ï¼Œå¯ä»¥æŸ¥çœ‹å„é¢˜å‹çš„ç‹¬ç«‹é¢˜ç›®æ–‡ä»¶")
        
        print(f"\nğŸ‰ æ­¥éª¤ '{step}' å¤„ç†å®Œæˆï¼å·¥ä½œç›®å½•: {work_dir}")
        
        if step == "split-questions":
            print(f"\nğŸ“ ä½¿ç”¨è¯´æ˜ï¼š")
            print("1. æŸ¥çœ‹ç”Ÿæˆçš„é¢˜ç›®æ–‡ä»¶ï¼ŒéªŒè¯æ‹†åˆ†æ˜¯å¦æ­£ç¡®")
            print("2. æ£€æŸ¥ split_summary.md æ–‡ä»¶äº†è§£æ‹†åˆ†ç»Ÿè®¡")
            print("3. è¿è¡Œ 'python main.py --step process' ç»§ç»­AIå¤„ç†")
            print("4. æˆ–è€…æŸ¥çœ‹å„é¢˜å‹ç›®å½•ä¸­çš„ split_stats.md äº†è§£è¯¦ç»†ä¿¡æ¯")
    
    def _print_directory_tree(self, directory: str, indent: str = "") -> None:
        """æ‰“å°ç›®å½•æ ‘ç»“æ„"""
        try:
            items = sorted(os.listdir(directory))
            for i, item in enumerate(items):
                path = os.path.join(directory, item)
                is_last = i == len(items) - 1
                current_indent = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                
                if os.path.isdir(path):
                    print(f"{indent}{current_indent}{item}/")
                    next_indent = indent + ("    " if is_last else "â”‚   ")
                    # åªæ˜¾ç¤ºå‰å‡ ä¸ªå­é¡¹ï¼Œé¿å…è¾“å‡ºè¿‡é•¿
                    sub_items = sorted(os.listdir(path))[:5]
                    for j, sub_item in enumerate(sub_items):
                        sub_is_last = j == len(sub_items) - 1
                        sub_current_indent = "â””â”€â”€ " if sub_is_last else "â”œâ”€â”€ "
                        print(f"{next_indent}{sub_current_indent}{sub_item}")
                    if len(os.listdir(path)) > 5:
                        print(f"{next_indent}â””â”€â”€ ... (è¿˜æœ‰{len(os.listdir(path)) - 5}ä¸ªæ–‡ä»¶)")
                else:
                    print(f"{indent}{current_indent}{item}")
        except PermissionError:
            print(f"{indent}â””â”€â”€ [æƒé™ä¸è¶³]")
"""
æ ‡å‡†åŒ–å¤„ç†é€šç”¨å·¥å…·
"""

from __future__ import annotations

import os
import re
from typing import List, Optional, Tuple, Dict, Any
from datetime import datetime

from openpyxl import Workbook
from openpyxl.styles import Font, Alignment


def _read_markdown_content_lines(file_path: str) -> List[str]:
    """è¯»å–markdownæ–‡ä»¶ä¸­é¦–å°¾ä¸‰ä¸ªåå¼•å·ä¹‹é—´çš„å†…å®¹è¡Œã€‚"""
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    with open(file_path, 'r', encoding='utf-8') as f:
        all_lines = f.readlines()

    content_start = -1
    for i, line in enumerate(all_lines):
        if line.strip() == "```" and i > 0:
            content_start = i + 1
            break

    if content_start == -1:
        raise ValueError("æ— æ³•æ‰¾åˆ°markdownæ–‡æœ¬å†…å®¹")

    content_end = len(all_lines)
    for i in range(len(all_lines) - 1, 0, -1):
        if all_lines[i].strip() == "```":
            content_end = i
            break

    return all_lines[content_start:content_end]


def chunk_file_by_lines(file_path: str, lines_per_chunk: int) -> List[Tuple[List[str], Optional[List[str]]]]:
    """æŒ‰è¡Œæ•°åˆ‡åˆ†markdownå†…å®¹ï¼Œè¿”å› (chunk1, chunk2) åˆ—è¡¨ã€‚"""
    content_lines = _read_markdown_content_lines(file_path)

    chunks: List[Tuple[List[str], Optional[List[str]]]] = []
    for i in range(0, len(content_lines), lines_per_chunk):
        chunk1_start = i
        chunk1_end = min(i + lines_per_chunk, len(content_lines))
        chunk1 = content_lines[chunk1_start:chunk1_end]

        chunk2: Optional[List[str]] = None
        if chunk1_end < len(content_lines):
            chunk2_end = min(chunk1_end + lines_per_chunk, len(content_lines))
            chunk2 = content_lines[chunk1_end:chunk2_end]

        chunks.append((chunk1, chunk2))

    return chunks


def call_openai_with_retries(client: Any, model: str, prompt: str, max_retries: int, temperature: float = 0.1) -> Optional[str]:
    """å¸¦é‡è¯•çš„OpenAIå¯¹è¯è°ƒç”¨ã€‚"""
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=temperature,
            )
            return response.choices[0].message.content
        except Exception as exc:  # noqa: BLE001 - æ‰“å°å¼‚å¸¸ä¿¡æ¯
            print(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {exc}")
            if attempt == max_retries - 1:
                return None
    return None


def split_questions_by_separator(ai_response: str, separator: str = "=== é¢˜ç›®åˆ†éš”ç¬¦ ===") -> List[str]:
    """å°†æ ‡å‡†åŒ–æ–‡æœ¬æŒ‰åˆ†éš”ç¬¦æ‹†åˆ†ä¸ºé¢˜ç›®ï¼›è‹¥æ— åˆ†éš”ç¬¦ï¼Œå›é€€æŒ‰ '### è¯•é¢˜ ' å—æ‹†åˆ†ã€‚"""
    if not ai_response:
        return []

    # é¦–é€‰ï¼šæŒ‰ç…§æ˜¾å¼åˆ†éš”ç¬¦æ‹†åˆ†
    if separator in ai_response:
        parts = ai_response.split(separator)
        results: List[str] = []
        for part in parts:
            text = part.strip()
            if text:
                results.append(text)
        if results:
            return results

    # å›é€€ï¼šæ ¹æ® '### è¯•é¢˜ ' æ ‡é¢˜åˆ‡åˆ†
    # æ•è·ä»æ¯ä¸ª '### è¯•é¢˜ ' å¼€å¤´åˆ°ä¸‹ä¸€ä¸ª '### è¯•é¢˜ ' ä¹‹å‰çš„å†…å®¹
    pattern = r"(### è¯•é¢˜\s+\d+[\s\S]*?)(?=\n### è¯•é¢˜\s+\d+|$)"
    matches = re.findall(pattern, ai_response)
    fallback_results: List[str] = []
    for block in matches:
        text = block.strip()
        if text:
            fallback_results.append(text)
    return fallback_results


def save_markdown_chunk_result(chunk_index: int, questions: List[str], output_dir: str, question_type_name: str) -> None:
    """ä¿å­˜æŸä¸ªchunkçš„æ ‡å‡†åŒ–ç»“æœä¸ºmarkdownæ–‡ä»¶ã€‚"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    chunk_file = os.path.join(output_dir, f"standardized_chunk_{chunk_index:03d}.md")
    with open(chunk_file, 'w', encoding='utf-8') as f:
        f.write(f"# {question_type_name} - Chunk {chunk_index}\n\n")
        f.write(f"## æ ‡å‡†åŒ–æ—¶é—´\n{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"## é¢˜ç›®æ•°é‡\n{len(questions)}\n\n")
        f.write("## æ ‡å‡†åŒ–é¢˜ç›®\n\n")
        for i, question in enumerate(questions, 1):
            f.write(f"### é¢˜ç›® {i}\n\n")
            f.write(f"```\n{question}\n```\n\n")

    print(f"âœ… Chunk {chunk_index}: ä¿å­˜ {len(questions)} é“é¢˜ç›®åˆ° {chunk_file}")


def save_original_chunk_file(chunk_index: int, chunk1: List[str], output_dir: str) -> None:
    """ä¿å­˜åŸå§‹chunkå†…å®¹åˆ°markdownæ–‡ä»¶ã€‚"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    chunk_file = os.path.join(output_dir, f"original_chunk_{chunk_index:03d}.md")
    with open(chunk_file, 'w', encoding='utf-8') as f:
        f.write(f"# åŸå§‹ Chunk {chunk_index}\n\n")
        f.write(f"## ç”Ÿæˆæ—¶é—´\n{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("## åˆ†å—å†…å®¹\n\n")
        f.write(''.join(chunk1))

    print(f"ğŸ’¾ åŸå§‹ Chunk {chunk_index} å·²ä¿å­˜åˆ°: {chunk_file}")


def list_standardized_chunk_files(standardized_dir: str) -> List[str]:
    """åˆ—å‡ºæ ‡å‡†åŒ–ç›®å½•ä¸‹æ‰€æœ‰æ ‡å‡†åŒ–chunkæ–‡ä»¶ï¼ˆæŒ‰åºï¼‰ã€‚"""
    files = [
        os.path.join(standardized_dir, f)
        for f in os.listdir(standardized_dir)
        if f.startswith('standardized_chunk_') and f.endswith('.md')
    ]
    files.sort()
    return files


def extract_codeblocks_from_markdown(content: str) -> List[str]:
    """ä»markdownæ–‡æœ¬ä¸­æå–æ‰€æœ‰ä¸‰åå¼•å·åŒ…è£¹çš„ä»£ç å—å†…å®¹ã€‚"""
    return re.findall(r"```\n(.*?)\n```", content, re.DOTALL)


def write_excel(headers: List[str], rows: List[List[Any]], sheet_title: str, output_path: str) -> None:
    """åˆ›å»ºExcelå¹¶å†™å…¥è¡¨å¤´ä¸è¡Œæ•°æ®ï¼Œè‡ªåŠ¨åˆ—å®½ã€‚"""
    wb = Workbook()
    ws = wb.active
    ws.title = sheet_title

    for col, header in enumerate(headers, 1):
        cell = ws.cell(row=1, column=col, value=header)
        cell.font = Font(bold=True)
        cell.alignment = Alignment(horizontal='center', vertical='center')

    for row_index, row_values in enumerate(rows, 2):
        for col_index, value in enumerate(row_values, 1):
            ws.cell(row=row_index, column=col_index, value=value)

    for column in ws.columns:
        max_length = 0
        column_letter = column[0].column_letter
        for cell in column:
            try:
                if len(str(cell.value)) > max_length:
                    max_length = len(str(cell.value))
            except Exception:
                pass
        adjusted_width = min(max_length + 2, 50)
        ws.column_dimensions[column_letter].width = adjusted_width

    wb.save(output_path)
    print(f"âœ… Excelæ–‡ä»¶å·²ä¿å­˜: {output_path}")
    print(f"ğŸ“Š å…±å†™å…¥ {len(rows)} è¡Œ")


